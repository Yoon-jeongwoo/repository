{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTqrptxIjmpWAvzaMy89u5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yoon-jeongwoo/repository/blob/main/Bearing_arima.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNs76nB4-Ciu",
        "outputId": "023afadb-d2d8-45f4-88b3-50d81d9aaaf3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VIALSPB_9ajf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MultipleLocator\n",
        "import matplotlib.dates as mdates\n",
        "from datetime import datetime, time\n",
        "import seaborn as sns\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from sklearn.metrics import mean_squared_error\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 소스 파일 경로\n",
        "source_file_path = '/content/drive/MyDrive/archive/phm2012.zip'\n",
        "# 대상 파일 경로\n",
        "target_file_path = '/content/archive.zip'\n",
        "# 파일 복사\n",
        "shutil.copyfile(source_file_path, target_file_path)\n",
        "# ZIP 파일 경로\n",
        "zip_file_path = '/content/archive.zip'\n",
        "# 언집할 폴더 경로\n",
        "target_folder_path = '/content/dataset'\n",
        "# ZIP 파일 언집\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(target_folder_path)\n"
      ],
      "metadata": {
        "id": "vC0yRkLi9g65"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def csv_to_df(split_type, bearing):\n",
        "    colname = ['Hour', 'Minute', 'Second', 'microsecond', 'Horiz', 'Vert']\n",
        "\n",
        "    # CSV 파일들이 있는 디렉토리 경로\n",
        "    directory_path = f'/content/dataset/{split_type}/{bearing}'\n",
        "\n",
        "    # 디렉토리 내의 모든 CSV 파일 경로를 가져오기\n",
        "    file_paths = glob.glob(directory_path + '/*.csv')\n",
        "\n",
        "    # 파일 경로를 순서대로 정렬\n",
        "    file_paths = sorted(file_paths)\n",
        "\n",
        "    # 파일들을 담을 빈 DataFrame 생성\n",
        "    combined_data = pd.DataFrame()\n",
        "\n",
        "    # acc 파일만 불러오기 (파일명에 'acc'가 포함된 파일들)\n",
        "    acc_file_paths = [file_path for file_path in file_paths if 'acc' in file_path]\n",
        "\n",
        "    # 각 파일을 순회하며 데이터를 불러온 뒤 빈 DataFrame에 추가\n",
        "    for file_path in acc_file_paths:\n",
        "        df = pd.read_csv(file_path, names=colname, header=None)  # 첫 번째 행을 인덱스로 사용하지 않음\n",
        "        combined_data = pd.concat([combined_data, df], ignore_index=True, axis=0)\n",
        "\n",
        "    return combined_data\n"
      ],
      "metadata": {
        "id": "sW-FuLe99h9F"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_timestamp(df):\n",
        "    # Convert timestamp columns to integers and create a new DataFrame with these values\n",
        "    timestamp_integers = df[['Hour', 'Minute', 'Second', 'microsecond']].astype(int)\n",
        "    timestamp_integers.columns = ['hour', 'minute', 'second', 'microsecond']\n",
        "\n",
        "    # Combine the integer values to form a string in the format 'HH:MM:SS.microseconds'\n",
        "    df['timestamp'] = timestamp_integers.apply(lambda x: f\"{x['hour']:02d}:{x['minute']:02d}:{x['second']:02d}.{x['microsecond']:06d}\", axis=1)\n",
        "\n",
        "    # Convert the 'timestamp' column to a Pandas datetime object\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'], format='%H:%M:%S.%f')\n",
        "\n",
        "    # Remove the date part from the 'timestamp' column\n",
        "    df['timestamp'] = df['timestamp'].dt.time\n",
        "\n",
        "    df = df.drop(['Hour', 'Minute', 'Second', 'microsecond'], axis=1)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "34Nv4TWm9iBh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_dataframe(split_type, bearing):\n",
        "    df = csv_to_df(split_type, bearing)\n",
        "    df = convert_timestamp(df)\n",
        "    return df\n",
        "\n",
        "# Load the dataset\n",
        "Learning_Bearing1_1 = make_dataframe('Learning_set', 'Bearing1_1')\n",
        "\n",
        "# Use only 'Horiz' column for ARIMA\n",
        "data = Learning_Bearing1_1['Horiz']\n",
        "\n",
        "# Split the data into training and test sets\n",
        "split_ratio = 0.8\n",
        "train_size = int(split_ratio * len(data))\n",
        "train, test = data[:train_size], data[train_size:]\n",
        "\n",
        "# Build the ARIMA model\n",
        "p, d, q = 1, 1, 0  # ARIMA(p, d, q) 모델의 하이퍼파라미터 설정\n",
        "model = ARIMA(train, order=(p, d, q))\n",
        "model_fit = model.fit()\n",
        "\n",
        "# Make predictions\n",
        "predictions = model_fit.forecast(steps=len(test))\n",
        "\n",
        "# Calculate the mean squared error\n",
        "mse = mean_squared_error(test, predictions)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "\n",
        "# Plot the results\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(data.index, data.values, label='Original Data', color='blue')\n",
        "plt.plot(test.index, predictions, label='ARIMA Predictions', color='red')\n",
        "plt.xlabel('Timestamp')\n",
        "plt.ylabel('Acceleration')\n",
        "plt.title('ARIMA Predictions for Horizontal Acceler')"
      ],
      "metadata": {
        "id": "ORdSB4f59xM8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}